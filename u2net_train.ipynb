{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as standard_transforms\n",
    "from skimage import io, transform\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data_loader import TextSegDataset\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from u2net import U2NET\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "from PIL import ImageFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images = []\n",
    "masks = []\n",
    "\n",
    "images_path = 'data/image/'\n",
    "masks_path = 'data/semantic_label/'\n",
    "img_size = 500\n",
    "\n",
    "for path in glob.glob(images_path + '*'):\n",
    "    # img_tensor = torch.from_numpy(io.imread(path))\n",
    "    # img_resized = T.Resize((img_size, img_size))(img_tensor)\n",
    "    # images.append(img_resized)\n",
    "    images.append(io.imread(path))\n",
    "\n",
    "for path in glob.glob(masks_path + '*'):\n",
    "    # mask_tensor = torch.from_numpy(io.imread(path))\n",
    "    # mask_resized = T.Resize((img_size, img_size))(mask_tensor)\n",
    "    # masks.append(mask_resized)\n",
    "    masks.append(io.imread(path))\n",
    "\n",
    "images = np.array(images)\n",
    "masks = np.array(masks)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "images_path = 'data/image/'\n",
    "masks_path = 'data/semantic_label/'\n",
    "\n",
    "images_path_list = glob.glob(images_path + '*')\n",
    "mask_path_list = glob.glob(masks_path + '*')\n",
    "\n",
    "original_dataset = TextSegDataset(\n",
    "    images_paths=images_path_list,\n",
    "    masks_path=mask_path_list,\n",
    "    transform=False\n",
    ")\n",
    "\n",
    "modified_dataset = TextSegDataset(\n",
    "    images_paths=images_path_list,\n",
    "    masks_path=mask_path_list,\n",
    "    transform=True\n",
    ")\n",
    "\n",
    "augmented_dataset = original_dataset + modified_dataset"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "epoch_num = 1000\n",
    "batch_size = 10\n",
    "test_batch_size = 8\n",
    "train_num = len(images_path_list)\n",
    "validation_split = 0.15\n",
    "\n",
    "train_dataset_size = int(2 * train_num * (1 - validation_split))\n",
    "test_dataset_size = 2 * train_num - train_dataset_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(augmented_dataset, (train_dataset_size, test_dataset_size),\n",
    "                                                            generator=torch.Generator().manual_seed(721))\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=True, num_workers=1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "net = U2NET(3, 1)\n",
    "net.to(device)\n",
    "\n",
    "model_name = f'u2net_{datetime.datetime.now().date()}'\n",
    "\n",
    "checkpoint_name = 'u2net_2021-12-23_epoch_0_train_0.5615894327386778_test_0.4500891561835807.pth'\n",
    "# checkpoint_name = False\n",
    "folder_name = 'saved_models_rg/'\n",
    "if checkpoint_name:\n",
    "    net.load_state_dict(torch.load(folder_name + checkpoint_name, map_location=torch.device(device)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def muti_bce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, labels_v):\n",
    "    loss0 = nn.BCELoss(size_average=True)(d0, labels_v)\n",
    "    loss1 = nn.BCELoss(size_average=True)(d1, labels_v)\n",
    "    loss2 = nn.BCELoss(size_average=True)(d2, labels_v)\n",
    "    loss3 = nn.BCELoss(size_average=True)(d3, labels_v)\n",
    "    loss4 = nn.BCELoss(size_average=True)(d4, labels_v)\n",
    "    loss5 = nn.BCELoss(size_average=True)(d5, labels_v)\n",
    "    loss6 = nn.BCELoss(size_average=True)(d6, labels_v)\n",
    "\n",
    "    loss = loss0 + loss1 + loss2 + loss3 + loss4 + loss5 + loss6\n",
    "\n",
    "    return loss0, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#optimizer = optim.Adagrad(net.parameters(), lr=0.00001, eps=1e-08, weight_decay=1e-4)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001, eps=1e-08, weight_decay=1e-6,amsgrad=True)\n",
    "#optimizer = optim.RMSprop(net.parameters(), lr=0.00001, eps=1e-08, weight_decay=1e-6, centered=True)\n",
    "\n",
    "for epoch in range(0, epoch_num):\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    test_loss = 0\n",
    "\n",
    "    for i, train_data in enumerate(train_dataloader):\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_inputs = train_data['image'].to(device)\n",
    "        train_labels = train_data['mask'].to(device)\n",
    "\n",
    "        # y zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        d0, d1, d2, d3, d4, d5, d6 = net(train_inputs)\n",
    "\n",
    "        _, loss = muti_bce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, train_labels)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        # # print statistics\n",
    "        train_loss += loss.data.item()\n",
    "\n",
    "        end_time = time.time()\n",
    "        eta = (end_time - start_time) * (train_dataset_size - (i + 1) * batch_size) / batch_size\n",
    "        print(\n",
    "            f\"epoch: {epoch + 1}/{epoch_num} eta:{int(eta)} s batch: {(i + 1)}/{int(train_dataset_size / batch_size)},\"\n",
    "            f\" loss: {train_loss / (i + 1)} \")\n",
    "\n",
    "    print('testing')\n",
    "    with torch.no_grad():\n",
    "        for j, test_data in enumerate(test_dataloader):\n",
    "            test_inputs = test_data['image'].to(device)\n",
    "            test_labels = test_data['mask'].to(device)\n",
    "\n",
    "            d0, d1, d2, d3, d4, d5, d6 = net(test_inputs)\n",
    "            _, loss = muti_bce_loss_fusion(d0, d1, d2, d3, d4, d5, d6, test_labels)\n",
    "\n",
    "            # # print statistics\n",
    "            test_loss += loss.data.item()\n",
    "\n",
    "    print(\n",
    "        f\"epoch: {epoch + 1}/{epoch_num} loss: {train_loss * batch_size / train_dataset_size} test loss: {test_loss * batch_size / test_dataset_size} \")\n",
    "\n",
    "    torch.save(net.state_dict(),\n",
    "               folder_name + model_name + f\"_epoch_{epoch}_train_{train_loss * batch_size / train_dataset_size}_test_{test_loss * batch_size / test_dataset_size}.pth\")\n",
    "    # train_loss = 0.0\n",
    "    net.train()  # resume train\n",
    "#   train_step_save = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def save_output(img, mask):\n",
    "    mask = mask.squeeze()\n",
    "\n",
    "    image=Image.fromarray(img)\n",
    "    # Конвертируем диапазон (0.0, 1.0) -> (0, 255)\n",
    "    mask = mask.transpose(0,1).cpu().data.numpy() * 255\n",
    "    # Перегоняем в pillow\n",
    "    mask = Image.fromarray(mask).convert(\"L\")\n",
    "    # Увеличиваем до размера исходного изображения\n",
    "    mask = mask.resize(image.size, resample=Image.BILINEAR)\n",
    "    # Оригинал перегоняем в RGBA\n",
    "    image.convert('RGBA')\n",
    "    # Заполняем альфа канал\n",
    "    image.putalpha(mask)\n",
    "    # Сохраняем\n",
    "    return mask,image"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "creatives_folder = \"creatives/\"\n",
    "image_size=500\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "net = U2NET(3, 1)\n",
    "net.to(device)\n",
    "\n",
    "checkpoint_name = 'u2net_2021-12-23_epoch_0_train_0.5615894327386778_test_0.4500891561835807.pth'\n",
    "# checkpoint_name = False\n",
    "folder_name = 'saved_models_rg/'\n",
    "\n",
    "net.load_state_dict(torch.load(folder_name + checkpoint_name, map_location=torch.device(device)))\n",
    "\n",
    "net.eval()\n",
    "\n",
    "for path in glob.glob(creatives_folder+'*'):\n",
    "    img=io.imread(path)\n",
    "    image_tensor = torch.from_numpy(img.astype(np.float32) / 255).transpose( 0, 2).to(device)\n",
    "    image_tensor = T.Resize((image_size, image_size))(image_tensor).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        d1, d2, d3, d4, d5, d6, d7 = net(image_tensor[None,:,:,:])\n",
    "\n",
    "    # Забираем из d1 маску\n",
    "    # В остальных d# тоже маски но хуже качеством\n",
    "    mask = d1[:, 0, :, :]\n",
    "\n",
    "    # сохраняем результат\n",
    "    mask,image=save_output(img, mask)\n",
    "\n",
    "    save_name=path[len(creatives_folder)+2:-3] + \"result.png\"\n",
    "\n",
    "    fig,(ax1,ax2)=plt.subplots(1,2,figsize=(15,15))\n",
    "\n",
    "    ax1.imshow(image)\n",
    "    ax1.set_title('image')\n",
    "\n",
    "    ax2.imshow(mask,cmap='gray')\n",
    "    ax2.set_title('mask')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    del d1, d2, d3, d4, d5, d6, d7"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "glob.glob('creatives/'+'*')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}